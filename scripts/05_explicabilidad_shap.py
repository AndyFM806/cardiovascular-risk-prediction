import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import shap
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

print("üîç AN√ÅLISIS DE EXPLICABILIDAD CON SHAP")
print("=" * 45)
print("Universidad Privada Antenor Orrego")
print("IA Explicable para Predicci√≥n Cardiovascular")
print("=" * 45)

try:
    # Cargar datos y modelo
    print("\nüìä Cargando datos y modelo...")
    
    X_test = np.load('models/X_test.npy')
    y_test = np.load('models/y_test.npy')
    
    with open('models/feature_names.txt', 'r') as f:
        feature_names = [line.strip() for line in f.readlines()]
    
    # Cargar el mejor modelo (asumiendo que es XGBoost)
    best_model = joblib.load('models/best_model.pkl')
    
    print(f"‚úÖ Datos cargados: {X_test.shape[0]:,} registros de prueba")
    print(f"‚úÖ Modelo cargado exitosamente")
    print(f"‚úÖ Caracter√≠sticas: {len(feature_names)}")
    
    # Convertir a DataFrame para mejor manejo
    X_test_df = pd.DataFrame(X_test, columns=feature_names)
    
    print("\nüß† INICIALIZANDO EXPLICADOR SHAP")
    print("-" * 40)
    
    # Crear explicador SHAP
    # Para modelos tree-based como XGBoost y Random Forest
    if hasattr(best_model, 'predict_proba'):
        explainer = shap.Explainer(best_model, X_test_df[:100])  # Usar muestra para eficiencia
        print("‚úÖ Explicador SHAP inicializado (TreeExplainer)")
    else:
        # Para otros modelos
        explainer = shap.KernelExplainer(best_model.predict_proba, X_test_df[:100])
        print("‚úÖ Explicador SHAP inicializado (KernelExplainer)")
    
    # Calcular valores SHAP para una muestra
    print("\nüìà CALCULANDO VALORES SHAP")
    print("-" * 40)
    
    # Usar una muestra m√°s peque√±a para eficiencia
    sample_size = min(500, len(X_test_df))
    X_sample = X_test_df.sample(n=sample_size, random_state=42)
    
    print(f"Calculando SHAP para {sample_size} muestras...")
    shap_values = explainer(X_sample)
    
    print("‚úÖ Valores SHAP calculados exitosamente")
    
    print("\nüéØ AN√ÅLISIS DE IMPORTANCIA GLOBAL")
    print("-" * 40)
    
    # Importancia global de caracter√≠sticas
    feature_importance = np.abs(shap_values.values).mean(0)
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': feature_importance
    }).sort_values('importance', ascending=False)
    
    print("Top 10 caracter√≠sticas m√°s importantes (SHAP):")
    for i, (_, row) in enumerate(importance_df.head(10).iterrows()):
        print(f"   {i+1:2d}. {row['feature']:<15}: {row['importance']:.4f}")
    
    print("\nüìä AN√ÅLISIS DE CASOS ESPEC√çFICOS")
    print("-" * 40)
    
    # Analizar casos espec√≠ficos
    # Caso de alto riesgo
    high_risk_idx = np.argmax(best_model.predict_proba(X_sample)[:, 1])
    high_risk_case = X_sample.iloc[high_risk_idx]
    high_risk_prob = best_model.predict_proba(X_sample.iloc[[high_risk_idx]])[:, 1][0]
    
    print(f"üî¥ CASO DE ALTO RIESGO (Probabilidad: {high_risk_prob:.1%})")
    print("Caracter√≠sticas principales:")
    
    # Obtener valores SHAP para este caso
    case_shap = shap_values[high_risk_idx]
    case_contributions = pd.DataFrame({
        'feature': feature_names,
        'value': high_risk_case.values,
        'shap_value': case_shap.values,
        'contribution': np.abs(case_shap.values)
    }).sort_values('contribution', ascending=False)
    
    for i, (_, row) in enumerate(case_contributions.head(5).iterrows()):
        direction = "‚Üë" if row['shap_value'] > 0 else "‚Üì"
        print(f"   {i+1}. {row['feature']}: {row['value']:.2f} {direction} ({row['shap_value']:+.3f})")
    
    # Caso de bajo riesgo
    low_risk_idx = np.argmin(best_model.predict_proba(X_sample)[:, 1])
    low_risk_case = X_sample.iloc[low_risk_idx]
    low_risk_prob = best_model.predict_proba(X_sample.iloc[[low_risk_idx]])[:, 1][0]
    
    print(f"\nüü¢ CASO DE BAJO RIESGO (Probabilidad: {low_risk_prob:.1%})")
    print("Caracter√≠sticas principales:")
    
    case_shap_low = shap_values[low_risk_idx]
    case_contributions_low = pd.DataFrame({
        'feature': feature_names,
        'value': low_risk_case.values,
        'shap_value': case_shap_low.values,
        'contribution': np.abs(case_shap_low.values)
    }).sort_values('contribution', ascending=False)
    
    for i, (_, row) in enumerate(case_contributions_low.head(5).iterrows()):
        direction = "‚Üë" if row['shap_value'] > 0 else "‚Üì"
        print(f"   {i+1}. {row['feature']}: {row['value']:.2f} {direction} ({row['shap_value']:+.3f})")
    
    print("\nüí° INTERPRETACI√ìN DE VALORES SHAP")
    print("-" * 40)
    print("‚Ä¢ Valores SHAP positivos (+): Aumentan el riesgo cardiovascular")
    print("‚Ä¢ Valores SHAP negativos (-): Disminuyen el riesgo cardiovascular")
    print("‚Ä¢ Magnitud del valor: Indica la fuerza del impacto")
    print("‚Ä¢ Suma de valores SHAP = Predicci√≥n - Valor base del modelo")
    
    print("\nüîç PATRONES IDENTIFICADOS")
    print("-" * 40)
    
    # Analizar patrones en los valores SHAP
    shap_df = pd.DataFrame(shap_values.values, columns=feature_names)
    
    # Caracter√≠sticas que m√°s aumentan el riesgo
    positive_impact = shap_df.mean().sort_values(ascending=False)
    print("Caracter√≠sticas que M√ÅS AUMENTAN el riesgo (promedio):")
    for i, (feature, impact) in enumerate(positive_impact.head(5).items()):
        if impact > 0:
            print(f"   {i+1}. {feature}: +{impact:.4f}")
    
    # Caracter√≠sticas que m√°s disminuyen el riesgo
    negative_impact = shap_df.mean().sort_values(ascending=True)
    print("\nCaracter√≠sticas que M√ÅS DISMINUYEN el riesgo (promedio):")
    for i, (feature, impact) in enumerate(negative_impact.head(5).items()):
        if impact < 0:
            print(f"   {i+1}. {feature}: {impact:.4f}")
    
    print("\nüìã RECOMENDACIONES BASADAS EN SHAP")
    print("-" * 40)
    
    # Generar recomendaciones basadas en el an√°lisis SHAP
    recommendations = []
    
    # Analizar las caracter√≠sticas m√°s importantes
    top_features = importance_df.head(5)['feature'].tolist()
    
    if 'age' in top_features:
        recommendations.append("La edad es un factor de riesgo no modificable, pero otros factores pueden compensar su efecto")
    
    if 'ap_hi' in top_features or 'ap_lo' in top_features:
        recommendations.append("La presi√≥n arterial es un factor cr√≠tico - su control puede reducir significativamente el riesgo")
    
    if 'bmi' in top_features:
        recommendations.append("El √≠ndice de masa corporal tiene gran impacto - mantener peso saludable es fundamental")
    
    if 'smoke' in top_features:
        recommendations.append("El tabaquismo es un factor de alto impacto modificable - dejar de fumar reduce dram√°ticamente el riesgo")
    
    if 'active' in top_features:
        recommendations.append("La actividad f√≠sica regular es protectora contra enfermedades cardiovasculares")
    
    print("Recomendaciones cl√≠nicas basadas en el an√°lisis:")
    for i, rec in enumerate(recommendations, 1):
        print(f"   {i}. {rec}")
    
    print("\n‚úÖ AN√ÅLISIS DE EXPLICABILIDAD COMPLETADO")
    print("üéØ El modelo es interpretable y sus decisiones pueden explicarse")
    print("üìä Los valores SHAP proporcionan insights valiosos para la pr√°ctica cl√≠nica")
    print("üí° La IA explicable aumenta la confianza en las predicciones m√©dicas")
    
    # Guardar resultados del an√°lisis SHAP
    shap_analysis = {
        'global_importance': importance_df.to_dict('records'),
        'high_risk_case': {
            'probability': float(high_risk_prob),
            'top_contributors': case_contributions.head(5).to_dict('records')
        },
        'low_risk_case': {
            'probability': float(low_risk_prob),
            'top_contributors': case_contributions_low.head(5).to_dict('records')
        },
        'recommendations': recommendations,
        'interpretation_guide': {
            'positive_shap': "Aumenta el riesgo cardiovascular",
            'negative_shap': "Disminuye el riesgo cardiovascular",
            'magnitude': "Indica la fuerza del impacto"
        }
    }
    
    import json
    with open('models/shap_analysis.json', 'w') as f:
        json.dump(shap_analysis, f, indent=2)
    
    print("üìÅ An√°lisis SHAP guardado en 'shap_analysis.json'")
    
except Exception as e:
    print(f"‚ùå Error en el an√°lisis SHAP: {str(e)}")
    print("Nota: SHAP requiere instalaci√≥n adicional: pip install shap")
    import traceback
    traceback.print_exc()
